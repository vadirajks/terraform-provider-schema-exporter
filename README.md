Terraform Provider Schema ExporterPython scripts to parse the output of terraform providers schema -json into organized and human-readable .tf, .yaml, and .json file trees.What is this?The terraform providers schema -json command is a powerful way to get the entire schema for one or more providers. However, its output is a single, massive JSON file (often 20MB+) that is impossible to navigate.These scripts solve that problem. They read the giant schema.json file and split it into thousands of individual files, organized by provider and schema type (resource, data source, etc.).This creates a human-readable "schema library" that you can browse, search, and use as a reference.Core FeaturesGenerates .tf Syntax: Creates .tf files that look like Terraform code, making them easy to read.Sorts Arguments: .tf files are sorted with (Required) arguments at the top of each block.Labels Blocks: Nested blocks are labeled as (Required) or (Optional).Cleans Descriptions: All \n and \t characters are stripped from descriptions for clean YAML and JSON output.Handles All Schemas: Correctly processes resource_schemas, data_source_schemas, resource_identity_schemas, and all other schema types.Project Structure.
├── all.sh                  # <-- Main script to run everything
├── extract_schema_json.py  #
├── extract_schema_tf.py    # <-- Core Python scripts
├── extract_schema_yaml.py  #
├── main.tf                 # <-- Your provider definitions
├── output/                 # <-- All generated files land here
│   ├── aws_schema_json/
│   ├── aws_schema_tf/
│   ├── aws_schema_yaml/
│   ├── azurerm_schema_json/
│   ├── ...
├── README.md
├── schema.json             # <-- Generated by 'all.sh'
├── split_schema_json.sh    #
├── split_schema_tf.sh      # <-- Helper scripts
└── split_schema_yaml.sh    #
How to UsePrerequisitesTerraform: Must be installed.Python 3: Must be installed.PyYAML: The only Python dependency.pip install pyyaml
Step 1: Configure ProvidersEdit the main.tf file to include all the providers you want to export. You do not need to specify a version.main.tfterraform {
  required_providers {
    google = {
      source  = "hashicorp/google"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
    }
    aws = {
      source  = "hashicorp/aws"
    }
  }
}
Step 2: Configure Helper ScriptsThe split_*.sh scripts tell the Python scripts which providers to extract from the main schema.json. If you added a new provider to main.tf (e.g., kubernetes), you must also add it to all three split_*.sh scripts.split_schema_tf.sh (Example)python3 extract_schema_tf.py \
  --provider google \
  --schema-json schema.json \
  --base-dir ./output

python3 extract_schema_tf.py \
  --provider aws \
  --schema-json schema.json \
  --base-dir ./output

python3 extract_schema_tf.py \
  --provider azurerm \
  --schema-json schema.json \
  --base-dir ./output
Step 3: Run the ExporterThe all.sh script automates the entire process.Make the script executable:chmod +x all.sh
Run the script:./all.sh
This script will:Run terraform init to download the providers.Run terraform providers schema -json > schema.json to create the master schema file.Execute all three split_*.sh scripts to generate the output directories.Step 4: Browse the OutputYou can now browse the generated schemas in the output/ directory.The tree structure will look like this:output/
├── aws_schema_tf
│   └── provider_schemas
│       └── registry_terraform_io_hashicorp_aws
│           ├── data_source_schemas
│           │   ├── aws_instance.tf
│           │   └── ...
│           ├── provider
│           │   └── aws.tf
│           ├── resource_identity_schemas
│           │   ├── aws_iam_role.tf
│           │   └── ...
│           └── resource_schemas
│               ├── aws_instance.tf
│               └── ...
├── azurerm_schema_tf
│   └── ...
└── google_schema_tf
    └── ...
Example OutputThe generated .tf files are formatted for readability, with required arguments and blocks listed first.Example: output/aws_schema_tf/.../resource_schemas/aws_instance.tfresource "aws_instance" "name" {
  // Required arguments
  ami = string (Required)
  instance_type = string (Required)

  // Optional arguments
  associate_public_ip_address = bool (Optional)
  availability_zone = string (Optional, Computed)
  cpu_core_count = number (Optional, Computed)
  // ...

  capacity_reservation_specification block "list" (Optional) {
    // Optional arguments
    capacity_reservation_preference = string (Optional)

    capacity_reservation_target block "list" (Optional) {
      // Optional arguments
      capacity_reservation_id = string (Optional)
      capacity_reservation_resource_group_arn = string (Optional)
    }
  }

  ebs_block_device block "set" (Optional, Computed) {
    // Required arguments
    device_name = string (Required)
    // ...
  }
  // ...

  // Computed arguments
  arn = string (Computed)
  id = string (Computed)
  primary_network_interface_id = string (Computed)
  // ...
}
