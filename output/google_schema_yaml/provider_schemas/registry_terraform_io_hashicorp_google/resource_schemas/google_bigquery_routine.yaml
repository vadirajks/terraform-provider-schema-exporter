version: 0
block:
  attributes:
    creation_time:
      type: number
      description: The time when this routine was created, in milliseconds since the epoch.
      description_kind: plain
      computed: true
    data_governance_type:
      type: string
      description: 'If set to DATA_MASKING, the function is validated and made available as a masking function. For more information, see https://cloud.google.com/bigquery/docs/user-defined-functions#custom-mask Possible values: ["DATA_MASKING"]'
      description_kind: plain
      optional: true
    dataset_id:
      type: string
      description: The ID of the dataset containing this routine
      description_kind: plain
      required: true
    definition_body:
      type: string
      description: The body of the routine. For functions, this is the expression in the AS clause. If language=SQL, it is the substring inside (but excluding) the parentheses.
      description_kind: plain
      required: true
    description:
      type: string
      description: The description of the routine if defined.
      description_kind: plain
      optional: true
    determinism_level:
      type: string
      description: 'The determinism level of the JavaScript UDF if defined. Possible values: ["DETERMINISM_LEVEL_UNSPECIFIED", "DETERMINISTIC", "NOT_DETERMINISTIC"]'
      description_kind: plain
      optional: true
    id:
      type: string
      description_kind: plain
      optional: true
      computed: true
    imported_libraries:
      type:
      - list
      - string
      description: Optional. If language = "JAVASCRIPT", this field stores the path of the imported JAVASCRIPT libraries.
      description_kind: plain
      optional: true
    language:
      type: string
      description: 'The language of the routine. Possible values: ["SQL", "JAVASCRIPT", "PYTHON", "JAVA", "SCALA"]'
      description_kind: plain
      optional: true
    last_modified_time:
      type: number
      description: The time when this routine was modified, in milliseconds since the epoch.
      description_kind: plain
      computed: true
    project:
      type: string
      description_kind: plain
      optional: true
      computed: true
    return_table_type:
      type: string
      description: Optional. Can be set only if routineType = "TABLE_VALUED_FUNCTION". If absent, the return table type is inferred from definitionBody at query time in each query that references this routine. If present, then the columns in the evaluated table result will be cast to match the column types specificed in return table type, at query time.
      description_kind: plain
      optional: true
    return_type:
      type: string
      description: 'A JSON schema for the return type. Optional if language = "SQL"; required otherwise. If absent, the return type is inferred from definitionBody at query time in each query that references this routine. If present, then the evaluated result will be cast to the specified returned type at query time. ~>**NOTE**: Because this field expects a JSON string, any changes to the string will create a diff, even if the JSON itself hasn''t changed. If the API returns a different value for the same schema, e.g. it switche d the order of values or replaced STRUCT field type with RECORD field type, we currently cannot suppress the recurring diff this causes. As a workaround, we recommend using the schema as returned by the API.'
      description_kind: plain
      optional: true
    routine_id:
      type: string
      description: The ID of the the routine. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum length is 256 characters.
      description_kind: plain
      required: true
    routine_type:
      type: string
      description: 'The type of routine. Possible values: ["SCALAR_FUNCTION", "PROCEDURE", "TABLE_VALUED_FUNCTION"]'
      description_kind: plain
      required: true
    security_mode:
      type: string
      description: 'Optional. The security mode of the routine, if defined. If not defined, the security mode is automatically determined from the routine''s configuration. Possible values: ["DEFINER", "INVOKER"]'
      description_kind: plain
      optional: true
  block_types:
    arguments:
      nesting_mode: list
      block:
        attributes:
          argument_kind:
            type: string
            description: 'Defaults to FIXED_TYPE. Default value: "FIXED_TYPE" Possible values: ["FIXED_TYPE", "ANY_TYPE"]'
            description_kind: plain
            optional: true
          data_type:
            type: string
            description: 'A JSON schema for the data type. Required unless argumentKind = ANY_TYPE. ~>**NOTE**: Because this field expects a JSON string, any changes to the string will create a diff, even if the JSON itself hasn''t changed. If the API returns a different value for the same schema, e.g. it switched the order of values or replaced STRUCT field type with RECORD field type, we currently cannot suppress the recurring diff this causes. As a workaround, we recommend using the schema as returned by the API.'
            description_kind: plain
            optional: true
          mode:
            type: string
            description: 'Specifies whether the argument is input or output. Can be set for procedures only. Possible values: ["IN", "OUT", "INOUT"]'
            description_kind: plain
            optional: true
          name:
            type: string
            description: The name of this argument. Can be absent for function return argument.
            description_kind: plain
            optional: true
        description: Input/output argument of a function or a stored procedure.
        description_kind: plain
    remote_function_options:
      nesting_mode: list
      block:
        attributes:
          connection:
            type: string
            description: 'Fully qualified name of the user-provided connection object which holds the authentication information to send requests to the remote service. Format: "projects/{projectId}/locations/{locationId}/connections/{connectionId}"'
            description_kind: plain
            optional: true
          endpoint:
            type: string
            description: Endpoint of the user-provided remote service, e.g. 'https://us-east1-my_gcf_project.cloudfunctions.net/remote_add'
            description_kind: plain
            optional: true
          max_batching_rows:
            type: string
            description: Max number of rows in each batch sent to the remote service. If absent or if 0, BigQuery dynamically decides the number of rows in a batch.
            description_kind: plain
            optional: true
          user_defined_context:
            type:
            - map
            - string
            description: 'User-defined context as a set of key/value pairs, which will be sent as function invocation context together with batched arguments in the requests to the remote service. The total number of bytes of keys and values must be less than 8KB. An object containing a list of "key": value pairs. Example: ''{ "name": "wrench", "mass": "1.3kg", "count": "3" }''.'
            description_kind: plain
            optional: true
            computed: true
        description: Remote function specific options.
        description_kind: plain
      max_items: 1
    spark_options:
      nesting_mode: list
      block:
        attributes:
          archive_uris:
            type:
            - list
            - string
            description: Archive files to be extracted into the working directory of each executor. For more information about Apache Spark, see Apache Spark.
            description_kind: plain
            optional: true
            computed: true
          connection:
            type: string
            description: 'Fully qualified name of the user-provided Spark connection object. Format: "projects/{projectId}/locations/{locationId}/connections/{connectionId}"'
            description_kind: plain
            optional: true
          container_image:
            type: string
            description: Custom container image for the runtime environment.
            description_kind: plain
            optional: true
          file_uris:
            type:
            - list
            - string
            description: Files to be placed in the working directory of each executor. For more information about Apache Spark, see Apache Spark.
            description_kind: plain
            optional: true
            computed: true
          jar_uris:
            type:
            - list
            - string
            description: JARs to include on the driver and executor CLASSPATH. For more information about Apache Spark, see Apache Spark.
            description_kind: plain
            optional: true
            computed: true
          main_class:
            type: string
            description: The fully qualified name of a class in jarUris, for example, com.example.wordcount. Exactly one of mainClass and main_jar_uri field should be set for Java/Scala language type.
            description_kind: plain
            optional: true
          main_file_uri:
            type: string
            description: The main file/jar URI of the Spark application. Exactly one of the definitionBody field and the mainFileUri field must be set for Python. Exactly one of mainClass and mainFileUri field should be set for Java/Scala language type.
            description_kind: plain
            optional: true
          properties:
            type:
            - map
            - string
            description: 'Configuration properties as a set of key/value pairs, which will be passed on to the Spark application. For more information, see Apache Spark and the procedure option list. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
            description_kind: plain
            optional: true
            computed: true
          py_file_uris:
            type:
            - list
            - string
            description: 'Python files to be placed on the PYTHONPATH for PySpark application. Supported file types: .py, .egg, and .zip. For more information about Apache Spark, see Apache Spark.'
            description_kind: plain
            optional: true
            computed: true
          runtime_version:
            type: string
            description: Runtime version. If not specified, the default runtime version is used.
            description_kind: plain
            optional: true
        description: Optional. If language is one of "PYTHON", "JAVA", "SCALA", this field stores the options for spark stored procedure.
        description_kind: plain
      max_items: 1
    timeouts:
      nesting_mode: single
      block:
        attributes:
          create:
            type: string
            description_kind: plain
            optional: true
          delete:
            type: string
            description_kind: plain
            optional: true
          update:
            type: string
            description_kind: plain
            optional: true
        description_kind: plain
  description_kind: plain
